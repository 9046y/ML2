{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate, which is calculated manually is: 0.750000\n",
      "Accuracy Rate, which is calculated by accuracy_score() is: 0.750000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Input training data\n",
    "training_points = [[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]]\n",
    "training_labels = [1, 1, 1, 2, 2, 2]\n",
    "X = np.array(training_points)\n",
    "Y = np.array(training_labels)\n",
    "\n",
    "# Create Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# Classify test data with the classifier\n",
    "test_points = [[1, 1], [2, 2], [3, 3], [4, 3]]\n",
    "test_labels = [2, 2, 2, 1]\n",
    "predicts = clf.predict(test_points)\n",
    "\n",
    "# Calculate Accuracy Rate manually\n",
    "count = len([\"ok\" for idx, label in enumerate(test_labels) if label == predicts[idx]])\n",
    "print( \"Accuracy Rate, which is calculated manually is: %f\" % (float(count) / len(test_labels)))\n",
    "\n",
    "# Calculate Accuracy Rate by using accuracy_score()\n",
    "print (\"Accuracy Rate, which is calculated by accuracy_score() is: %f\" % accuracy_score(test_labels, predicts))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "----------\n",
    "It’s the ratio between the number of correct predictions and the total number of predictions (the number of data points in the test set): \n",
    "accuracy = # correct predictions / total number of predictions\n",
    "\n",
    "Accuracy = (Number of elements correctly classified)/(Total elements)\n",
    "\n",
    " It is really only suitable when there are an equal number of observations in each class (which is rarely the case) and that all predictions and prediction errors are equally important, which is often not the case.\n",
    "\n",
    "When the classes are imbalanced, i.e., there are a lot more examples of one class than the other, then the accu‐ racy will give a very distorted picture, because the class with more examples will dominate the statistic. In that case, you should look at the per-class accuracy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
